{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Tweets\n",
    "\n",
    "** Thank you to Lukas Biewald for the Machine Learning class. **\n",
    "\n",
    "The original tutorial is here:\n",
    "    - https://s3.amazonaws.com/ai-learn-l2k/ML_Course.pdf\n",
    "    - https://github.com/lukas/ml-class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4573\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('tweets.csv')\n",
    "target = df['is_there_an_emotion_directed_at_a_brand_or_product']\n",
    "text = df['tweet_text']\n",
    "\n",
    "fixed_text = text[pd.notnull(text)]\n",
    "fixed_target = target[pd.notnull(text)]\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect=CountVectorizer()\n",
    "count_vect.fit(fixed_text)\n",
    "\n",
    "print(count_vect.vocabulary_.get(u'iphone'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    .@wesley83 I have a 3G iPhone. After 3 hrs twe...\n",
      "1    @jessedee Know about @fludapp ? Awesome iPad/i...\n",
      "Name: tweet_text, dtype: object\n",
      "  (0, 168)\t1\n",
      "  (0, 430)\t1\n",
      "  (0, 774)\t2\n",
      "  (0, 2291)\t1\n",
      "  (0, 3981)\t1\n",
      "  (0, 4210)\t1\n",
      "  (0, 4573)\t1\n",
      "  (0, 4610)\t1\n",
      "  (0, 5766)\t1\n",
      "  (0, 6478)\t1\n",
      "  (0, 7232)\t1\n",
      "  (0, 8076)\t1\n",
      "  (0, 8323)\t1\n",
      "  (0, 8702)\t1\n",
      "  (0, 8920)\t1\n",
      "  (0, 9062)\t1\n",
      "  (0, 9303)\t1\n",
      "  (0, 9373)\t1\n",
      "  (1, 313)\t1\n",
      "  (1, 527)\t1\n",
      "  (1, 644)\t1\n",
      "  (1, 677)\t1\n",
      "  (1, 774)\t1\n",
      "  (1, 876)\t1\n",
      "  (1, 2386)\t1\n",
      "  (1, 3356)\t1\n",
      "  (1, 3401)\t1\n",
      "  (1, 3454)\t1\n",
      "  (1, 3685)\t1\n",
      "  (1, 4560)\t1\n",
      "  (1, 4573)\t1\n",
      "  (1, 4619)\t1\n",
      "  (1, 4678)\t1\n",
      "  (1, 4847)\t1\n",
      "  (1, 5042)\t1\n",
      "  (1, 5094)\t1\n",
      "  (1, 6913)\t1\n",
      "  (1, 8323)\t1\n",
      "  (1, 8560)\t1\n",
      "  (1, 8602)\t1\n",
      "  (1, 8870)\t1\n",
      "  (1, 9625)\t1\n"
     ]
    }
   ],
   "source": [
    "# turns the text into a sparse matrix\n",
    "counts = count_vect.transform(fixed_text)\n",
    "print(fixed_text[0:2])\n",
    "print(counts[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.\n",
      "\n",
      "0    .@wesley83 I have a 3G iPhone. After 3 hrs twe...\n",
      "1    @jessedee Know about @fludapp ? Awesome iPad/i...\n",
      "Name: tweet_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# some other fun things to try\n",
    "print(fixed_text[0])\n",
    "print(count_vect.transform([\"cerulean\"]))\n",
    "print(fixed_text[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.67032967  0.66813187  0.62087912  0.64285714  0.64945055  0.67912088\n",
      "  0.67876788  0.6809681   0.66041896  0.63947078]\n",
      "0.659039495078\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "p = Pipeline(steps=[('counts', CountVectorizer(ngram_range=(1, 2))),\n",
    "                ('feature_selection', SelectKBest(chi2, k=10000)),\n",
    "                ('multinomialnb', MultinomialNB())])\n",
    "\n",
    "p.fit(fixed_text, fixed_target)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(p, fixed_text, fixed_target, cv=10)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Positive emotion']\n"
     ]
    }
   ],
   "source": [
    "# Train with this data with a Naive Bayes classifier:\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(counts, fixed_target)\n",
    "\n",
    "#Try the classifier\n",
    "print(nb.predict(count_vect.transform(['i love my iphone'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: I love my iphone!!!\n",
      "Prediction: ['Positive emotion']\n",
      "\n",
      "\n",
      "Tweet: iphone costs too much!!!\n",
      "Prediction: ['Negative emotion']\n",
      "\n",
      "\n",
      "Tweet: the iphone is not good\n",
      "Prediction: ['Positive emotion']\n",
      "\n",
      "\n",
      "Tweet: I like turtles\n",
      "Prediction: ['No emotion toward brand or product']\n",
      "\n",
      "\n",
      "Tweet: I have a love/hate relationship with my iphone\n",
      "Prediction: ['Negative emotion']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See what the classifier predicts for some new tweets:\n",
    "for tweet in ('I love my iphone!!!', 'iphone costs too much!!!', 'the iphone is not good', 'I like turtles', 'I have a love/hate relationship with my iphone'):\n",
    "  print('Tweet: ' + tweet)\n",
    "  print('Prediction: ' + str(nb.predict(count_vect.transform([tweet]))))\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of correct predictions: 7229\n",
      "# of incorrect predictions: 1863\n",
      "Percent correct: 79.5094588649\n"
     ]
    }
   ],
   "source": [
    "# See what the classifier predicts for some new tweets:\n",
    "predictions = nb.predict(counts)\n",
    "correct_predictions = sum(predictions == fixed_target)\n",
    "incorrect_predictions = 9092 - correct_predictions  # (there are 9,092 tweets in the csv)\n",
    "\n",
    "print('# of correct predictions: ' + str(correct_predictions))\n",
    "print('# of incorrect predictions: ' + str(incorrect_predictions))\n",
    "print('Percent correct: ' + str(100.0 * correct_predictions / (correct_predictions + incorrect_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of correct predictions: 1797\n",
      "# of incorrect predictions: 1295\n",
      "Percent correct: 58.1177231565\n"
     ]
    }
   ],
   "source": [
    "nb.fit(counts[0:6000], target[0:6000])\n",
    "\n",
    "# See what the classifier predicts for some new tweets:\n",
    "# (Tweets 6000 to 9091 are used for testing)\n",
    "predictions = nb.predict(counts[6000:9092])\n",
    "correct_predictions = sum(predictions == fixed_target[6000:9092])\n",
    "incorrect_predictions = (9092 - 6000) - correct_predictions\n",
    "print('# of correct predictions: ' + str(correct_predictions))\n",
    "print('# of incorrect predictions: ' + str(incorrect_predictions))\n",
    "print('Percent correct: ' + str(100.0 * correct_predictions / (correct_predictions + incorrect_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels in data:\n",
      "['Positive emotion', 'No emotion toward brand or product', 'Negative emotion']\n",
      "Rows: actual labels, Columns: Predicted labels\n",
      "[[ 229  743   15]\n",
      " [ 407 1474    9]\n",
      " [  43  119    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "## We're ignoring \"I can't tell\" here for simplicity\n",
    "label_list = ['Positive emotion', 'No emotion toward brand or product', 'Negative emotion'] \n",
    "cm = confusion_matrix(target[6000:9092], predictions, labels=label_list)\n",
    "print(\"Labels in data:\")\n",
    "print(label_list)\n",
    "print(\"Rows: actual labels, Columns: Predicted labels\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use DummyClassifer as a simple baseline to compare with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No emotion toward brand or product']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "nb = DummyClassifier(strategy='most_frequent')\n",
    "nb.fit(counts, fixed_target)\n",
    "print(nb.predict(count_vect.transform(['i love my iphone'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of correct predictions: 5388\n",
      "# of incorrect predictions: 3704\n",
      "Percent correct: 59.2608886934\n"
     ]
    }
   ],
   "source": [
    "predictions = nb.predict(counts)\n",
    "\n",
    "correct_predictions = sum(predictions == fixed_target)\n",
    "incorrect_predictions = 9092 - correct_predictions  # (there are 9,092 tweets in the csv)\n",
    "print('# of correct predictions: ' + str(correct_predictions))\n",
    "print('# of incorrect predictions: ' + str(incorrect_predictions))\n",
    "print('Percent correct: ' + str(100.0 * correct_predictions / (correct_predictions + incorrect_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of correct predictions: 1890\n",
      "# of incorrect predictions: 1202\n",
      "Percent correct: 61.1254851229\n"
     ]
    }
   ],
   "source": [
    "nb.fit(counts[0:6000], fixed_target[0:6000])\n",
    "\n",
    "# See what the classifier predicts for some new tweets:\n",
    "# (Tweets 6000 to 9091 are used for testing)\n",
    "predictions = nb.predict(counts[6000:9092])\n",
    "correct_predictions = sum(predictions == fixed_target[6000:9092])\n",
    "incorrect_predictions = (9092 - 6000) - correct_predictions\n",
    "print('# of correct predictions: ' + str(correct_predictions))\n",
    "print('# of incorrect predictions: ' + str(incorrect_predictions))\n",
    "print('Percent correct: ' + str(100.0 * correct_predictions / (correct_predictions + incorrect_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels in data:\n",
      "['Positive emotion', 'No emotion toward brand or product', 'Negative emotion']\n",
      "Rows: actual labels, Columns: Predicted labels\n",
      "[[   0  988    0]\n",
      " [   0 1890    0]\n",
      " [   0  162    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "## We're ignoring \"I can't tell\" here for simplicity\n",
    "label_list = ['Positive emotion', 'No emotion toward brand or product', 'Negative emotion'] \n",
    "cm = confusion_matrix(fixed_target[6000:9092], predictions, labels=label_list)\n",
    "print(\"Labels in data:\")\n",
    "print(label_list)\n",
    "print(\"Rows: actual labels, Columns: Predicted labels\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Perceptron linear mode as comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.63516484  0.65274725  0.64175824  0.63626374  0.62087912  0.61428571\n",
      "  0.62706271  0.58305831  0.53031974  0.45644983]\n",
      "0.599798948321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "perceptron = Perceptron()\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(perceptron, counts, fixed_target, cv=10)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8972973   0.90163934  0.83977901  0.92222222  0.91620112  0.92178771\n",
      "  0.93296089  0.92696629  0.85310734  0.88636364]\n",
      "0.899832486311\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "scores = cross_val_score(perceptron, digits.data, digits.target, cv=10)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
